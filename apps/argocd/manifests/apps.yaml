apiVersion: argoproj.io/v1alpha1
kind: AppProject
metadata:
  name: k3s
spec:
  clusterResourceWhitelist:
  - group: '*'
    kind: '*'
  description: Home automation and management
  destinations:
  - name: in-cluster
    namespace: '*'
    server: https://kubernetes.default.svc
  namespaceResourceWhitelist:
  - group: '*'
    kind: '*'
  sourceRepos:
  - https://github.com/sholdee/home-ops
---
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: k3s-apps
spec:
  goTemplate: true
  goTemplateOptions: ["missingkey=error"]
  generators:
    - git:
        repoURL: https://github.com/sholdee/home-ops
        revision: master
        directories:
          - path: 'apps/*'
  template:
    metadata:
      name: '{{.path.basename}}'
      annotations:
        argocd.argoproj.io/compare-options: ServerSideDiff=true
    spec:
      project: k3s
      source:
        repoURL: https://github.com/sholdee/home-ops
        targetRevision: master
        path: '{{.path.path}}'
      destination:
        name: in-cluster
        namespace: '{{ regexReplaceAll "-conf$" .path.basename "" }}'
      syncPolicy:
        automated:
          prune: true
        syncOptions:
        - CreateNamespace=true
        - ApplyOutOfSyncOnly=true
        - RespectIgnoreDifferences=true
        - ServerSideApply=true
  templatePatch: |
    {{- if eq .path.basename "kubernetes-dashboard" }}
    spec:
      ignoreDifferences:
      - group: '*'
        kind: ConfigMap
        name: kubernetes-dashboard-web-settings
        jsonPointers:
        - /data
      - group: '*'
        kind: Secret
        name: kubernetes-dashboard-csrf
        jsonPointers:
        - /data/private.key
      - group: apps
        kind: Deployment
        jsonPointers:
        - /spec/template/metadata/annotations/checksum~1config
    {{- end }}
    {{- if eq .path.basename "kube-prometheus-stack" }}
    spec:
      destination:
        name: in-cluster
        namespace: monitoring
    {{- end }}
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: 1password-connect
spec:
  destination:
    name: in-cluster
    namespace: external-secrets
  project: k3s
  source:
    chart: connect
    helm:
      valuesObject:
        connect:
          replicas: 2
          serviceType: ClusterIP
          credentialsName: op-credentials
          credentialsKey: 1password-credentials.json
          api:
            resources:
              requests:
                cpu: 5m
                memory: 64Mi
              limits:
                memory: 64Mi
          sync:
            resources:
              requests:
                cpu: 5m
                memory: 64Mi
              limits:
                memory: 64Mi
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchExpressions:
                      - key: app
                        operator: In
                        values:
                          - onepassword-connect
                  topologyKey: kubernetes.io/hostname
    repoURL: https://1password.github.io/connect-helm-charts
    targetRevision: 1.17.0
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
    - ApplyOutOfSyncOnly=true
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: cilium
  annotations:
    argocd.argoproj.io/compare-options: ServerSideDiff=true
spec:
  destination:
    name: in-cluster
    namespace: kube-system
  ignoreDifferences:
    - jsonPointers:
      - /data/ca.crt
      - /data/ca.key
      kind: Secret
      name: cilium-ca
    - jsonPointers:
      - /data/ca.crt
      kind: Secret
      name: hubble-ca-cert
    - jsonPointers:
      - /data
      kind: Secret
      name: hubble-relay-client-certs
    - jsonPointers:
      - /data
      kind: Secret
      name: hubble-server-certs
  project: k3s
  source:
    chart: cilium
    helm:
      releaseName: cilium
      valuesObject:
        cluster:
          name: k3s
          id: 7
        ipam:
          operator:
            clusterPoolIPv4PodCIDRList: "10.52.0.0/16"
        ipv4NativeRoutingCIDR: "10.52.0.0/16"
        k8sServiceHost: "127.0.0.1"
        k8sServicePort: "6444"
        routingMode: "native"
        autoDirectNodeRoutes: true
        kubeProxyReplacement: true
        bpf:
          masquerade: false
          datapathMode: "netkit"
        loadBalancer:
          algorithm: "maglev"
          mode: "dsr"
        enableIPv4Masquerade: false
        bgpControlPlane:
          enabled: true
        hubble:
          enabled: true
          relay:
            enabled: true
          ui:
            enabled: true
        installNoConntrackIptablesRules: true
        operator:
          replicas: 3
          prometheus:
            enabled: true
            serviceMonitor:
              enabled: true
          dashboards:
            enabled: true
        prometheus:
          enabled: true
          serviceMonitor:
            enabled: true
            trustCRDsExist: true
        dashboards:
          enabled: true
        gatewayAPI:
          enabled: true
    repoURL: https://helm.cilium.io/
    targetRevision: 1.17.4
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - ServerSideApply=true
    - RespectIgnoreDifferences=true
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: etcd-operator
  annotations:
    argocd.argoproj.io/compare-options: ServerSideDiff=true
spec:
  destination:
    name: in-cluster
    namespace: etcd-operator
  project: k3s
  source:
    chart: etcd-operator
    helm:
      valuesObject:
        etcdOperator:
          vpa:
            enabled: false
          resources:
            limits:
              cpu: 150m
              memory: 200Mi
            requests:
              cpu: 3m
              memory: 200Mi
        kubeRbacProxy:
          vpa:
            enabled: false
          resources:
            limits:
              cpu: 150m
              memory: 128Mi
            requests:
              cpu: 3m
              memory: 128Mi
        podSecurityContext:
          runAsNonRoot: true
          runAsUser: 65534
          runAsGroup: 65534
          fsGroup: 65534
          fsGroupChangePolicy: "OnRootMismatch"
          seccompProfile:
            type: RuntimeDefault
    repoURL: ghcr.io/aenix-io/charts
    targetRevision: 0.4.2
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
    - ServerSideApply=true
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ingress-nginx
spec:
  destination:
    name: in-cluster
    namespace: ingress-nginx
  project: k3s
  source:
    chart: ingress-nginx
    helm:
      valuesObject:
        controller:
          service:
            internal:
              loadBalancerIP: "192.168.77.20"
          extraArgs:
            default-ssl-certificate: "default/mgmt-wildcard"
          metrics:
            enabled: true
            serviceMonitor:
              enabled: true
            prometheusRule:
              enabled: true
              rules:
                - alert: NGINXConfigFailed
                  expr: count(nginx_ingress_controller_config_last_reload_successful == 0) > 0
                  for: 1s
                  labels:
                    severity: critical
                  annotations:
                    description: bad ingress config - nginx config test failed
                    summary: uninstall the latest ingress changes to allow config reloads to resume
                - alert: NGINXCertificateExpiry
                  expr: (avg(nginx_ingress_controller_ssl_expire_time_seconds) by (host) - time()) < 604800
                  for: 1s
                  labels:
                    severity: critical
                  annotations:
                    description: ssl certificate(s) will expire in less then a week
                    summary: renew expiring certificates to avoid downtime
                - alert: NGINXTooMany500s
                  expr: 100 * ( sum( nginx_ingress_controller_requests{status=~"5.+"} ) / sum(nginx_ingress_controller_requests) ) > 25
                  for: 1m
                  labels:
                    severity: warning
                  annotations:
                    description: Too many 5XXs
                    summary: More than 25% of all requests returned 5XX, this requires your attention
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                    - key: app.kubernetes.io/name
                      operator: In
                      values:
                      - ingress-nginx
                    - key: app.kubernetes.io/instance
                      operator: In
                      values:
                      - ingress-nginx
                    - key: app.kubernetes.io/component
                      operator: In
                      values:
                      - controller
                  topologyKey: kubernetes.io/hostname
          resources:
            requests:
              cpu: 100m
              memory: 250Mi
            limits:
              memory: 250Mi
    repoURL: https://kubernetes.github.io/ingress-nginx
    targetRevision: 4.12.2
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
    - ApplyOutOfSyncOnly=true
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: longhorn
spec:
  destination:
    name: in-cluster
    namespace: longhorn-system
  ignoreDifferences:
  - group: '*'
    kind: CustomResourceDefinition
    jsonPointers:
    - /spec/preserveUnknownFields
  project: k3s
  source:
    chart: longhorn
    helm:
      valuesObject:
        defaultSettings:
          defaultDataLocality: best-effort
          concurrentAutomaticEngineUpgradePerNodeLimit: "2"
          nodeDownPodDeletionPolicy: delete-both-statefulset-and-deployment-pod
          nodeDrainPolicy: block-for-eviction-if-contains-last-replica
          replicaAutoBalance: best-effort
          backupTarget: "nfs://10.2.0.110:/volume1/longhorn"
          backupTargetCredentialSecret: ""
          backupstorePollInterval: "3600"
          removeSnapshotsDuringFilesystemTrim: "true"
        metrics:
          serviceMonitor:
            enabled: "true"
        networkPolicies:
          enabled: false
          type: "k3s"
    repoURL: https://charts.longhorn.io
    targetRevision: 1.8.1
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - ApplyOutOfSyncOnly=true
    - CreateNamespace=true
    - RespectIgnoreDifferences=true
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: mongodb-community-operator
spec:
  destination:
    name: in-cluster
    namespace: mongodb
  project: k3s
  source:
    chart: community-operator
    helm:
      valuesObject:
        operator:
          replicas: 1
          watchNamespace: "*"
          resources:
            limits:
              memory: 100Mi
            requests:
              cpu: 20m
              memory: 100Mi
    repoURL: https://mongodb.github.io/helm-charts
    targetRevision: 0.13.0
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - ApplyOutOfSyncOnly=true
    - CreateNamespace=true
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: reloader
spec:
  destination:
    name: in-cluster
    namespace: default
  project: k3s
  source:
    chart: reloader
    helm:
      valuesObject:
        fullnameOverride: reloader
        reloader:
          readOnlyRootFileSystem: true
          podMonitor:
            enabled: true
    repoURL: https://stakater.github.io/stakater-charts
    targetRevision: 2.1.3
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - ApplyOutOfSyncOnly=true
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: volsync
spec:
  destination:
    name: in-cluster
    namespace: volsync-system
  project: k3s
  source:
    chart: volsync
    helm:
      valuesObject:
        image:
          tag: "0.13.0-rc.1"
        restic:
          tag: "0.13.0-rc.1"
        replicaCount: 2
        manageCRDs: true
        metrics:
          disableAuth: true
    repoURL: https://backube.github.io/helm-charts/
    targetRevision: 0.12.1
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - ApplyOutOfSyncOnly=true
    - CreateNamespace=true
